{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d802096",
   "metadata": {},
   "source": [
    "# resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b827b91a",
   "metadata": {},
   "source": [
    "在深层神经网络训练过程中, 会出现准确率随着网络深度增加(在一个已经达到较好的效果的浅层网络上加入恒等映射层), 先增大后减小, 神经网络会退化. 过深的网络无法拟合线性映射. 因此需要使用残差方法."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbadfcd",
   "metadata": {},
   "source": [
    "在神经网络优化中, 如果在某一层以后需要一个恒等映射$H(x) = x$来拟合下一层的函数, 对于多层网络而言很困难, 于是需要一个残差函数$H(x)  = F(x) + x$来让网络学习$F(x) = H(x) - x$ 来避免直接对恒等映射直接学习, 如果此处函数应该是恒等映射的话, 那么只需要学习到$F(x) == 0$即可. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fe90c6",
   "metadata": {},
   "source": [
    "此处网络连接成为shortcut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4483896",
   "metadata": {},
   "source": [
    "![shortcut](shortcut.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702354e",
   "metadata": {},
   "source": [
    "假设shortcut从$m$层进行映射, 假设$m+1$层(可以跨越多层)可能学习为恒等映射, 那么为了防止直接学习恒等映射. 在第$m+2$层加入$m$层的原始数据, 这样, 如果需要拟合为恒等映射, 只需要将$m+1$层函数置为零即可(对于ReLU只需要让其变为负数, 即可变为零)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4226c920",
   "metadata": {},
   "source": [
    "![pic](mtom2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80462aad",
   "metadata": {},
   "source": [
    "对于此矩阵表达式为(bias算在$X$内)\n",
    "$$Y^{(m+2)} = ReLU(X^{(m+1)}W_{m+2} + X^{(m)}W_s) \\\\\n",
    " X^{(m+1)} = ReLU(X^{(m)}W_{m+1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132429de",
   "metadata": {},
   "source": [
    "$W_s$是变换矩阵, 用于匹配将$m$层矩阵映射到$m+2$层时同型可加. 一般采用全零padding或者使用1\\*1卷积核对其变化维度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
